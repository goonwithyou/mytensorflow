{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单的两个数组相加案例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 6])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([1,2], name='a')\n",
    "b = tf.constant([3,4], name='b')\n",
    "result = a + b\n",
    "sess = tf.Session()\n",
    "sess.run(result)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 计算图Graph\n",
    "---\n",
    "```python\n",
    "import tensorflow as tf\n",
    "tf.Graph()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 计算图的使用\n",
    "---\n",
    "每个计算图相互独立"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph1 v =  [0.]\n",
      "Graph2 v =  [1.]\n"
     ]
    }
   ],
   "source": [
    "# 创建两个计算图，并定义一个初始化变量v\n",
    "g1 = tf.Graph()\n",
    "with g1.as_default():\n",
    "    v = tf.get_variable('v', shape=[1], initializer=tf.zeros_initializer)\n",
    "    \n",
    "g2 = tf.Graph()\n",
    "with g2.as_default():\n",
    "    v = tf.get_variable('v', shape=[1], initializer=tf.ones_initializer)\n",
    "    \n",
    "# 获取g1中的v\n",
    "with tf.Session(graph=g1) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    with tf.variable_scope('', reuse=True):\n",
    "        print('Graph1 v = ', sess.run(tf.get_variable('v')))\n",
    "\n",
    "# 获取g2中的v\n",
    "with tf.Session(graph=g2) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    with tf.variable_scope('', reuse=True):\n",
    "        print('Graph2 v = ', sess.run(tf.get_variable('v')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "指定图在GPU计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 6]\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "a = tf.constant([1,2], name='a')\n",
    "b = tf.constant([3,4], name='b')\n",
    "\n",
    "with g.device('/gpu:0'):\n",
    "    result = a + b\n",
    "    with tf.Session() as sess:\n",
    "        print(sess.run(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Tensor\n",
    "---\n",
    "### 1.2.1 introduction\n",
    "---\n",
    "1. tensor\n",
    "    - 0阶张量为标量(scalar)，对应一个数\n",
    "    - 一阶张量为向量(vector)，对应一维数组\n",
    "    - n阶张量对应n维数组\n",
    "2. tensor的数据结构\n",
    "    - name: `name:src_output`\n",
    "    - shape:\n",
    "    - dtype:\n",
    "3. tensor支持的数据类型\n",
    "    - tf.float32, tf.float64\n",
    "    - tf.int8, tf.int16, tf.int32, tf.int64, tf.uint8\n",
    "    - tf.bool\n",
    "    - tf.complex64, tf.complex128\n",
    "4. 张量的使用\n",
    "    - 对中间计算结果的引用\n",
    "    - 可以通过name获取保存的计算结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = tf.constant([1,2], name='a')\n",
    "b = tf.constant([3,4], name='b')\n",
    "result = tf.add(a, b, name='add_ab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_ab:0' shape=(2,) dtype=int32>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result\n",
    "# '节点名:该节点的第几个输出'，如果重复赋值，以前的不会被覆盖，会出现`add_ab_1:0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'a_12:0' shape=(2,) dtype=int32>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Session\n",
    "---\n",
    "tensorflow 通过使用Session来执行定义好的运算。\n",
    "```python\n",
    "sess = tf.Session()\n",
    "# 执行定义好的张量\n",
    "sess.run()\n",
    "\n",
    "sess.close()\n",
    "```\n",
    "or\n",
    "```python\n",
    "with tf.Session() as sess:\n",
    "    sess.run()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 定义默认会话\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**方法1**：使用as_default创建一个context manager，在内部可以直接使用tensor_name.eval()执行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 6]\n"
     ]
    }
   ],
   "source": [
    "# 使用as_default创建一个context manager，在内部可以直接使用tensor_name.eval()执行。\n",
    "sess = tf.Session()\n",
    "with sess.as_default():\n",
    "    print(result.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**方法2**：使用`tf.InteractiveSession()`函数,直接创建一个默认session，不用再去指定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 6]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "print(result.eval())\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**方法3**：使用`ConfigProto()`创建一个config对象，在session创建的时候指定config属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(allow_soft_placement=True,\n",
    "                       log_device_placement=True)\n",
    "\n",
    "sess1 = tf.InteractiveSession(config=config)\n",
    "# sess2 = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 实现神经网络\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([0.7, 0.9], shape=(2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = tf.constant([[0.2, 0.3],[0.1,-0.5],[0.4,0.2]], shape=(3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2 = tf.constant([0.6, 0.1, -0.2], shape=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.matmul(w1, x)\n",
    "y = tf.matmul(w2, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11600002]], dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1 variable\n",
    "---\n",
    "在tensorflow中，一个变量值在被使用之前，这个变量的**初始化过程**要被明确调用。变量定义类似于python中的函数定义，想要使用，需要调用。通过session调用。\n",
    "```python\n",
    "# 创建variable,并将变量加入到GraphKeys.VARIABLES,如果参数trainable=True,默认为True,则变量会被加入到GraphKeys.TRAINABLE_VARIABLES\n",
    "v = tf.Variable()\n",
    "# 初始化\n",
    "v.initializer\n",
    "\n",
    "# 获取已定义的变量列表\n",
    "tf.global_variables()\n",
    "\n",
    "# 获取可训练的变量列表\n",
    "tf.trainable_variables\n",
    "\n",
    "```\n",
    "\n",
    ">  随机生成函数\n",
    "---\n",
    "```python\n",
    "tf.random_normal\n",
    "tf.truncated_normal\n",
    "tf.random_uniform\n",
    "tf.random.gamma\n",
    "```\n",
    "\n",
    "> 常数生成函数\n",
    "---\n",
    "```python\n",
    "tf.zeros\n",
    "tf.ones\n",
    "tf.fill\n",
    "tf.constant\n",
    "```\n",
    "### 1.4.2 前向传播\n",
    "---\n",
    "1. 定义输入值\n",
    "2. 定义隐藏层1的权重\n",
    "3. 定义隐藏层2的权重\n",
    "4. 计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.7798672]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 定义输入值\n",
    "x = tf.constant([0.7,0.9], shape=(2, 1), dtype=tf.float32)\n",
    "\n",
    "# 随机生成权重值，采用正太分布\n",
    "w1 = tf.Variable(tf.random_normal((3, 2), stddev=1, seed=1))\n",
    "w2 = tf.Variable(tf.random_normal((1, 3), stddev=1, seed=1))\n",
    "\n",
    "# 定义计算过程\n",
    "h = tf.matmul(w1, x)\n",
    "y = tf.matmul(w2, h)\n",
    "\n",
    "# 定义全局变量初始化\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# 开始计算\n",
    "with tf.Session() as sess:\n",
    "#     sess.run(w1.initializer)\n",
    "#     sess.run(w2.initializer)\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.3 placeholder\n",
    "---\n",
    "用placeholder管理常量\n",
    "```python\n",
    "# 创建\n",
    "v = tf.placeholder(dtype, shape=None, name=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.7798672]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 定义输入值\n",
    "x = tf.placeholder(tf.float32, shape=(2, 1), name='input')\n",
    "\n",
    "# 随机生成权重值，采用正太分布\n",
    "w1 = tf.Variable(tf.random_normal((3, 2), stddev=1, seed=1))\n",
    "w2 = tf.Variable(tf.random_normal((1, 3), stddev=1, seed=1))\n",
    "\n",
    "# 定义计算过程\n",
    "h = tf.matmul(w1, x)\n",
    "y = tf.matmul(w2, h)\n",
    "\n",
    "# 定义全局变量初始化\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# 开始计算\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(y, feed_dict={x: [[0.7],[0.9]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义多维输入值,这里定义三个样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.7798674 -1.8407464 -3.4529805]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 定义输入值（三个样本）\n",
    "x = tf.placeholder(tf.float32, shape=(2, 3), name='input')\n",
    "\n",
    "# 随机生成权重值，采用正太分布\n",
    "w1 = tf.Variable(tf.random_normal((3, 2), stddev=1, seed=1))\n",
    "w2 = tf.Variable(tf.random_normal((1, 3), stddev=1, seed=1))\n",
    "\n",
    "# 定义计算过程\n",
    "h = tf.matmul(w1, x)\n",
    "y = tf.matmul(w2, h)\n",
    "\n",
    "# 定义全局变量初始化\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# 定义输入值\n",
    "input_data = np.array([[0.7, 0.9],\n",
    "                      [0.1, 0.4],\n",
    "                      [0.5, 0.8]]).T\n",
    "# 开始计算\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(y, feed_dict={x: input_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.4 反向传播\n",
    "---\n",
    "这里采用交叉熵\n",
    "$$H(p,q)=-\\sum_{i=1}^np(x_i)log(q(x_i))$$\n",
    "其中p为target值的概率，q为预测值的概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.5 完整的代码\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1-->\n",
      " [[-0.8113182   1.4845988   0.06532937]\n",
      " [-2.4427042   0.0992484   0.5912243 ]]\n",
      "w2-->\n",
      " [[-0.8113182 ]\n",
      " [ 1.4845988 ]\n",
      " [ 0.06532937]]\n",
      "After 0 , cross entropy is 1.89805\n",
      "After 1000 , cross entropy is 0.655075\n",
      "After 2000 , cross entropy is 0.626172\n",
      "After 3000 , cross entropy is 0.615096\n",
      "After 4000 , cross entropy is 0.610309\n",
      "new w1\n",
      " [[ 0.02476974  0.56948686  1.6921943 ]\n",
      " [-2.1977353  -0.23668927  1.1143897 ]]\n",
      "new w2\n",
      " [[-0.45544702]\n",
      " [ 0.49110925]\n",
      " [-0.98110336]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 定义batch的大小\n",
    "batch_size = 8\n",
    "\n",
    "# 定义输入值,这里不具体指定样本的数量\n",
    "x = tf.placeholder(tf.float32, shape=(None, 2), name='input')\n",
    "# 定义输出的label\n",
    "y_ = tf.placeholder(tf.float32, shape=(None, 1), name='target')\n",
    "\n",
    "# 随机生成权重值，采用正太分布\n",
    "w1 = tf.Variable(tf.random_normal((2, 3), stddev=1, seed=1))\n",
    "w2 = tf.Variable(tf.random_normal((3, 1), stddev=1, seed=1))\n",
    "\n",
    "# 定义计算过程\n",
    "h = tf.matmul(x, w1)\n",
    "y = tf.matmul(h, w2)\n",
    "\n",
    "# 对输出结果归一化处理\n",
    "y = tf.sigmoid(y)\n",
    "\n",
    "\n",
    "# 求交叉熵，衡量误差\n",
    "cross_entropy = -tf.reduce_mean(\n",
    "    y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0)) + (1 - y_) * tf.log(tf.clip_by_value(1 - y, 1e-10, 1.0))\n",
    ")\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)\n",
    "\n",
    "# 随机生成模拟数据集\n",
    "rdm = np.random.RandomState(1)\n",
    "dataset_size = 128\n",
    "X = rdm.rand(dataset_size, 2)\n",
    "\n",
    "# 确定target\n",
    "Y = [[int(x1 + x2 < 1)] for (x1, x2) in X]\n",
    "\n",
    "with tf.Session() as sess:   \n",
    "    # 定义全局变量初始化\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    \n",
    "    sess.run(init_op)\n",
    "    print('w1-->\\n', sess.run(w1))\n",
    "    print('w2-->\\n', sess.run(w2))\n",
    "\n",
    "    steps = 5000\n",
    "    for i in range(steps):\n",
    "        start = (i * batch_size) % dataset_size\n",
    "        end = min(start + batch_size, dataset_size)\n",
    "        sess.run(train_step, feed_dict={x: X[start: end], y_: Y[start: end]})\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            total_cross_entropy = sess.run(cross_entropy, feed_dict={x: X, y_: Y})\n",
    "            print('After %d , cross entropy is %g' % (i, total_cross_entropy))\n",
    "    print('new w1\\n', sess.run(w1))\n",
    "    print('new w2\\n', sess.run(w2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 深层NN\n",
    "---\n",
    "## 2.1 常用的非线性激活函数\n",
    "---\n",
    "```python\n",
    "tf.nn.relu()\n",
    "tf.nn.sigmoid()\n",
    "tf.nn.tanh()\n",
    "```\n",
    "\n",
    "## 2.2 损失函数\n",
    "---\n",
    "1. 分类问题\n",
    "    - 交叉熵\n",
    "        - 先用softmax将输出结果转成概率分布的形式`tf.nn.softmax()`\n",
    "        - $$H(p, q) = - \\sum_xlog q(x)$$\n",
    "        - p为正确答案，q为预测答案，这里都可以用概率表示。整体的意义为用q的概率分布来表示p的概率分布的困难程度。\n",
    "        - p和q越接近，交叉熵的值越小。\n",
    "        ```python\n",
    "        # softmax + cross_entropy\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y)\n",
    "        # 只有一个正确答案的分类问题\n",
    "        tf.nn.softmax_sparse_softmax_cross_entropy_with_logits()\n",
    "        ```\n",
    "2. 回归问题\n",
    "    - MSE(mean squared error)\n",
    "    - $$MSE(y, y^{'}) = \\frac{\\sum_{i=1}^{n}(y_i - y_i^{'})^2}{n}$$\n",
    "    - MSE也常用于分类问题的损失函数\n",
    "    - `tf.reduce_mean(tf.square(y_ - y))`\n",
    "3. 自定义\n",
    "\n",
    "## 2.3 网络优化\n",
    "---\n",
    "### 1. 学习率\n",
    "- 指数衰减法\n",
    "```python\n",
    "    decayed_learning_rate = learning_rate *\n",
    "                    decay_rate ^ (global_step / decay_steps)\n",
    "```\n",
    "- learning_rate:学习率，dency_rate:衰减率，global_step:迭代次数，常为一个数值为0的tensor。decay_steps:衰减速度。eg:每迭代十万次，衰减率乘以0.96\n",
    "```python\n",
    "...\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "starter_learning_rate = 0.1\n",
    "learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "                                           100000, 0.96, staircase=True)\n",
    "# Passing global_step to minimize() will increment it at each step.\n",
    "learning_step = (\n",
    "    tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    .minimize(...my loss..., global_step=global_step)\n",
    ")\n",
    "```\n",
    "- 对应tf中的函数为：`tf.train.exponential_decay(learning_rate, global_step, decay_steps, decay_rate, staircase=False, name=None)`\n",
    "    - staircase为False，表示连续衰减\n",
    "    - staircase为True，表示阶梯衰减。\n",
    "    \n",
    "### 2. 过拟合\n",
    "- 正则化。正则化是处理过拟合常用的方法。**正则化是针对权重进行操作的**\n",
    "- L1正则化$$R(w) = \\lVert{w}\\rVert_1 = \\sum_i\\lvert{w_i}\\rvert$$\n",
    "- L2正则化$$R(w) = \\lVert{w}\\rVert_1^2 = \\sum_i\\lvert{w_i^2}\\rvert$$\n",
    "- L1和L2同时使用：$$R(w) = \\sum_i\\alpha\\lvert{w_i}\\rvert + (1 - \\alpha)w_i^2$$\n",
    "- 如果损失函数为$J(\\theta)$加入了正则化后，加会变成$J(\\theta) + \\lambda{R(w)}$\n",
    "- eg\n",
    "```python\n",
    "weights = tf.constant([[1.0, -2.0],[-3.0, 4.0]])\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.contrib.layers.l1_regularizer(0.5)(weights)))\n",
    "    print(sess.run(tf.contrib.layers.l2_regularizer(0.5)(weights)))\n",
    "    print(sess.run(tf.contrib.layers.l1_l2_regularizer(0.5)(weights)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下一个五层神经网络(3个隐藏层)，带有L2正则化的实现方法。(只是部分实现代码，不做具体实现)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 这里传入一个shape，随机生成一组权重值，并以lambda和权重值得到L2，并加入到tf的collection中\n",
    "def get_weight(shape, lamb):\n",
    "    # 依据给定的shape生成一组正太分布随机值\n",
    "    weights = tf.Variable(tf.random_normal(shape), dtype=tf.float32)\n",
    "    # 计算L2\n",
    "    L2 = tf.contrib.layers.l2_regularizer(lamb)(weights)\n",
    "    tf.add_to_collection('losses', L2)\n",
    "    return weights\n",
    "\n",
    "# 定义输入值\n",
    "x = tf.placeholder(tf.float32, shape=(None, 2))\n",
    "# 定义target值结构\n",
    "y_ = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "\n",
    "batch_size = 8\n",
    "# 定义每一层的节点数\n",
    "layer_dimension = [2, 10, 10, 10, 1]\n",
    "# 层数\n",
    "n_layers = len(layer_dimension)\n",
    "\n",
    "# 定义所在计算层\n",
    "cur_layer = x\n",
    "in_dimension = layer_dimension[0]\n",
    "\n",
    "for i in range(1, n_layers):\n",
    "    # 获取第一层的weights，先确定shape\n",
    "    out_dimension = layer_dimension[i]\n",
    "    weight = get_weight((in_dimension, out_dimension), 0.01)\n",
    "    # 更新当前层的输出值\n",
    "    bias = tf.Variable(tf.constant(0.1, shape=(out_dimension, 1)))\n",
    "    cur_layer = tf.matmul(cur_layer, weight) + bias\n",
    "    in_dimension = out_dimension\n",
    "    \n",
    "# 求损失函数，MSE\n",
    "mse_loss = tf.reduce_mean(tf.square(y_ - cur_layer))\n",
    "tf.add_to_collection('losses', mse_loss)\n",
    "\n",
    "# \n",
    "loss = tf.add_n(tf.get_collection('losses'))\n",
    "\n",
    "## ing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 滑动平均模型（作用？？）\n",
    "- 在每层的计算中，对权重和偏移量计算一个滑动平均(也理解为对所有神经网络参数的变量上使用滑动平均)\n",
    "- (可以使模型在测试数据上更加的robust).\n",
    "- 适用于**随机梯度下降**训练神经网络时\n",
    "- `tf.train.ExponentialMovingAverage(decay, num_updates=None, zero_debias=False, name='ExponentialMovingAverage')`\n",
    "    - decay越大模型越趋于稳定。\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1=0,step=0\n",
      "[0.0, 0.0]\n",
      "\n",
      "v1=5,step=0\n",
      "[5.0, 4.5]\n",
      "\n",
      "v1=10,step=1000\n",
      "[10.0, 4.555]\n",
      "\n",
      "v1=10, step=1000\n",
      "[10.0, 4.60945]\n"
     ]
    }
   ],
   "source": [
    "# 实现移动平均模型\n",
    "import tensorflow as tf\n",
    "\n",
    "v1 = tf.Variable(0, dtype=tf.float32)\n",
    "step = tf.Variable(0, trainable=False)\n",
    "\n",
    "ema = tf.train.ExponentialMovingAverage(0.99, step)\n",
    "maintain_average_op = ema.apply([v1])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    print('v1=0,step=0')\n",
    "    print(sess.run([v1, ema.average(v1)]))\n",
    "    \n",
    "    sess.run(tf.assign(v1, 5))\n",
    "    sess.run(maintain_average_op)\n",
    "    print('\\nv1=5,step=0')\n",
    "    print(sess.run([v1, ema.average(v1)]))\n",
    "    \n",
    "    sess.run(tf.assign(step, 1000))\n",
    "    sess.run(tf.assign(v1, 10))\n",
    "    sess.run(maintain_average_op)\n",
    "    print('\\nv1=10,step=1000')\n",
    "    print(sess.run([v1, ema.average(v1)]))\n",
    "    \n",
    "    print('\\nv1=10, step=1000')\n",
    "    sess.run(maintain_average_op)\n",
    "    print(sess.run([v1, ema.average(v1)]))     \n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 MNIST\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting D:/softfiles/workspace/tensorflow/data/train-images-idx3-ubyte.gz\n",
      "Extracting D:/softfiles/workspace/tensorflow/data/train-labels-idx1-ubyte.gz\n",
      "Extracting D:/softfiles/workspace/tensorflow/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting D:/softfiles/workspace/tensorflow/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('D:/softfiles/workspace/tensorflow/data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 完整案例\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting D:/softfiles/workspace/tensorflow/data/train-images-idx3-ubyte.gz\n",
      "Extracting D:/softfiles/workspace/tensorflow/data/train-labels-idx1-ubyte.gz\n",
      "Extracting D:/softfiles/workspace/tensorflow/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting D:/softfiles/workspace/tensorflow/data/t10k-labels-idx1-ubyte.gz\n",
      "After 0 training steps, validation accuracy using average model is 0.1116\n",
      "After 1000 training steps, validation accuracy using average model is 0.9792\n",
      "After 2000 training steps, validation accuracy using average model is 0.9818\n",
      "After 3000 training steps, validation accuracy using average model is 0.9828\n",
      "After 4000 training steps, validation accuracy using average model is 0.9834\n",
      "After 5000 training steps, validation accuracy using average model is 0.9838\n",
      "After 6000 training steps, validation accuracy using average model is 0.984\n",
      "After 7000 training steps, validation accuracy using average model is 0.9842\n",
      "After 8000 training steps, validation accuracy using average model is 0.9846\n",
      "After 9000 training steps, validation accuracy using average model is 0.9848\n",
      "After 10000 training steps, test accuracy using average model is 0.9846\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\softfiles\\programs\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2870: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 定义各层的节点数，这里只使用一个隐藏层\n",
    "INPUT_NODES = 28 * 28\n",
    "OUTPUT_NODES = 10\n",
    "HIDDEN_NODES = 500\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "# 定义滑动平均参数\n",
    "MOVING_AVERAGE_DECAY = 0.99\n",
    "\n",
    "# 定义正则化参数\n",
    "REGULARIZATION_RATE = 0.0001\n",
    "\n",
    "\n",
    "# 定义学习率优化参数\n",
    "LEARNING_RATE_BASE = 0.8\n",
    "LEARNING_RATE_DECAY = 0.99\n",
    "\n",
    "# 训练次数\n",
    "TRAINING_STEPS = 10000\n",
    "\n",
    "def getFinalOutput(input_tensor, weights1, biases1, weights2, biases2, avg_class=None):\n",
    "    if avg_class == None:\n",
    "        layer1 = tf.nn.relu(tf.matmul(input_tensor, weights1) + biases1)\n",
    "        return tf.matmul(layer1, weights2) + biases2\n",
    "    else:\n",
    "        layer1 = tf.nn.relu(tf.matmul(input_tensor, avg_class.average(weights1)) + avg_class.average(biases1))\n",
    "        return tf.matmul(layer1, avg_class.average(weights2)) + avg_class.average(biases2)\n",
    "\n",
    "\n",
    "def train(mnist):\n",
    "    # 定义输入值和输出值\n",
    "    x = tf.placeholder(tf.float32, shape=(None, INPUT_NODES), name='input')\n",
    "    y_ = tf.placeholder(tf.float32, shape=(None, OUTPUT_NODES), name='output')\n",
    "    \n",
    "    # 初始化权重和偏移量\n",
    "    weights1 = tf.Variable(tf.truncated_normal((INPUT_NODES, HIDDEN_NODES), stddev=0.1))\n",
    "    biases1 = tf.Variable(tf.constant(0.1, shape=(HIDDEN_NODES,)))\n",
    "    \n",
    "    weights2 = tf.Variable(tf.truncated_normal((HIDDEN_NODES, OUTPUT_NODES), stddev=0.1))\n",
    "    biases2 = tf.Variable(tf.constant(0.1, shape=(OUTPUT_NODES,)))\n",
    "    \n",
    "    # 定义一个没有滑动平均的输出值\n",
    "    output = getFinalOutput(x, weights1, biases1, weights2, biases2)\n",
    "    \n",
    "    # 创建滑动平均类\n",
    "    GLOBAL_STEP = tf.Variable(0, trainable=False)\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, GLOBAL_STEP)\n",
    "    variable_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "    \n",
    "    average_output = getFinalOutput(x, weights1, biases1, weights2, biases2, variable_averages)\n",
    "    \n",
    "    # 计算损失函数交叉熵+softmax\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=output, labels=tf.argmax(y_, 1))\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "    # 正则项\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(REGULARIZATION_RATE)\n",
    "    regularization = regularizer(weights1) + regularizer(weights2)\n",
    "    \n",
    "    # 最终损失函数\n",
    "    loss = cross_entropy_mean + regularization\n",
    "    \n",
    "    # 定义衰减学习率(指数衰减法)\n",
    "    LEARNING_RATE = tf.train.exponential_decay(LEARNING_RATE_BASE, GLOBAL_STEP, mnist.train.num_examples / BATCH_SIZE, LEARNING_RATE_DECAY)\n",
    "    \n",
    "    # 梯度下降更新权重值\n",
    "    gdo = tf.train.GradientDescentOptimizer(LEARNING_RATE)\n",
    "    train_step = gdo.minimize(loss, global_step = GLOBAL_STEP)\n",
    "    \n",
    "    # 打包更新操作，这里有两个动作，train_step,variable_averages_op\n",
    "    with tf.control_dependencies([train_step, variable_averages_op]):\n",
    "        train_op = tf.no_op(name='train')\n",
    "    \n",
    "    # 输出正确率\n",
    "    correct_predict = tf.equal(tf.argmax(average_output, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predict, tf.float32))\n",
    "    \n",
    "    # 初始会话\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        \n",
    "        validate_feed = {x: mnist.validation.images, y_: mnist.validation.labels}\n",
    "        test_feed = {x: mnist.validation.images, y_: mnist.validation.labels}\n",
    "        for i in range(TRAINING_STEPS):\n",
    "            if i % 1000 == 0:\n",
    "                validate_acc = sess.run(accuracy, validate_feed)\n",
    "                print('After %d training steps, validation accuracy using average model is %g' % (i, validate_acc))\n",
    "            xs, ys = mnist.train.next_batch(BATCH_SIZE)\n",
    "            sess.run(train_op, feed_dict={x: xs, y_: ys})\n",
    "        \n",
    "        test_acc = sess.run(accuracy, test_feed)\n",
    "        print('After %d training steps, test accuracy using average model is %g' % (TRAINING_STEPS, test_acc))\n",
    "    \n",
    "\n",
    "def main(argv=None):\n",
    "    mnist = input_data.read_data_sets('D:/softfiles/workspace/tensorflow/data/', one_hot=True)\n",
    "    train(mnist)\n",
    "    return 0\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 验证数据\n",
    "\n",
    "---\n",
    "1. 从训练数据中选取一部分做验证数据。\n",
    "2. 采用cross validation(对于大批量数据耗时交久，因为交叉验证常会测试多次)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 变量管理\n",
    "---\n",
    "### 创建变量\n",
    "```python\n",
    "tf.get_variable(name, shape, initializer) # 创建或获取\n",
    "tf.Variable()\n",
    "```\n",
    "\n",
    "### 获取变量\n",
    "```python\n",
    "tf.get_variable(name) # 要配合tf.variable_scope(name, reuse)生成一个context manager使用\n",
    "\n",
    "# reuse为True则获取域内变量，为False则在域内创建变量\n",
    "with tf.variable_scope('foo', reuse=False):\n",
    "    tf.get_variable('name')\n",
    "    \n",
    "#\n",
    "```\n",
    "\n",
    "### 变量初始化函数\n",
    "用于`tf.get_variable()中的initializer属性`\n",
    "```python\n",
    "# 常量初始化\n",
    "tf.constant_initializer()\n",
    "# 正太分布\n",
    "tf.random_normal_initializer()\n",
    "# 正太分布，偏离度在两个标准差内\n",
    "tf.truncated_normal_initializer()\n",
    "# 平均分布\n",
    "tf.random_uniform_initializer()\n",
    "# 平均分布\n",
    "tf.uniform_unit_scaling_initializer()\n",
    "tf.zeros_initializer()\n",
    "tf.ones_initializer()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 tf模型持久化\n",
    "---\n",
    "### 保存\n",
    "```python\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    saver.save(sess, '/path/to/model/model.ckpt')\n",
    "```\n",
    "- tf模型常采用 **.ckpt**为后缀名\n",
    "- 保存后会生成四个文件\n",
    "    - checkpoint\n",
    "    - model.ckpt.data-00000-of-00001 变量值\n",
    "    - model.ckpt.index 变量值\n",
    "    - model.ckpt.meta 保存计算图的结构\n",
    "\n",
    "### 读取\n",
    "```python\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    # 不需要变量初始化，直接读取保存的数据\n",
    "    saver.restore(sess, path)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**将变量保存到/moddel文件夹中**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "v1 = tf.Variable(tf.constant(1.0, shape=(1,)), name='v1')\n",
    "v2 = tf.Variable(tf.constant(2.0, shape=(1,)), name='v2')\n",
    "result = v1 + v2\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    saver.save(sess, './model/model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**读取保存的变量,不需要初始化操作,原则上所有变量只有经过初始化才会在加载到执行空间，因为之前保存的就是执行空间中的变量的值，所以不进行初始化也能操作。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/model.ckpt\n",
      "[3.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "v1 = tf.Variable(tf.constant(1.0, shape=(1,)), name='v1')\n",
    "v2 = tf.Variable(tf.constant(2.0, shape=(1,)), name='v2')\n",
    "result = v1 + v2\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './model/model.ckpt')\n",
    "    print(sess.run(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**也可以直接通过.meta文件读取计算图结构**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/model.ckpt\n",
      "[<tf.Variable 'v1:0' shape=(1,) dtype=float32_ref>, <tf.Variable 'v2:0' shape=(1,) dtype=float32_ref>]\n",
      "[3.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "saver = tf.train.import_meta_graph('./model/model.ckpt.meta')\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './model/model.ckpt')\n",
    "    print(tf.global_variables())\n",
    "    print(sess.run(tf.get_default_graph().get_tensor_by_name('add:0')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**保存滑动平均的shadow变量**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'v:0' shape=() dtype=float32_ref>]\n",
      "\n",
      "after ema-->\n",
      " [<tf.Variable 'v:0' shape=() dtype=float32_ref>, <tf.Variable 'v/ExponentialMovingAverage:0' shape=() dtype=float32_ref>]\n",
      "\n",
      "save-->\n",
      " [<tf.Variable 'v:0' shape=() dtype=float32_ref>, <tf.Variable 'v/ExponentialMovingAverage:0' shape=() dtype=float32_ref>]\n",
      "[10.0, 0.099999905]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "v = tf.Variable(0, dtype=tf.float32, name='v')\n",
    "print(tf.global_variables())\n",
    "\n",
    "ema = tf.train.ExponentialMovingAverage(0.99)\n",
    "average_op = ema.apply(tf.global_variables())\n",
    "print('\\nafter ema-->\\n', tf.global_variables())\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    sess.run(tf.assign(v, 10))\n",
    "    sess.run(average_op)\n",
    "    print('\\nsave-->\\n', tf.global_variables())\n",
    "    saver.save(sess, './model/model.ckpt')\n",
    "    print(sess.run([v, ema.average(v)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**取出保存的shadow变量**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'v/ExponentialMovingAverage': <tf.Variable 'v:0' shape=() dtype=float32_ref>}\n",
      "INFO:tensorflow:Restoring parameters from ./model/model.ckpt\n",
      "0.099999905\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "v = tf.Variable(0, dtype=tf.float32, name='v')\n",
    "ema = tf.train.ExponentialMovingAverage(0.99)\n",
    "print(ema.variables_to_restore())\n",
    "\n",
    "saver = tf.train.Saver(ema.variables_to_restore())\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './model/model.ckpt')\n",
    "    print(sess.run(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function run in module tensorflow.python.platform.app:\n",
      "\n",
      "run(main=None, argv=None)\n",
      "    Runs the program with an optional 'main' function and 'argv' list.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.app.run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([\n",
    "    [1,2],\n",
    "    [3,4],\n",
    "    [5,6]\n",
    "])\n",
    "b = np.array([2,2]).reshape([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 4],\n",
       "       [5, 6],\n",
       "       [7, 8]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "a = None\n",
    "if a is not None:\n",
    "    print(23)\n",
    "else:\n",
    "    print(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
