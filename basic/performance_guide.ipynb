{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Performance  Guide\n",
    "---\n",
    "- [General best parctices](#General-best-parctices)\n",
    "- [Optimizing for GPU](#Optimizing-for-GPU)\n",
    "- [Optimizing for CPU](#Optimizing-for-CPU)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## General best parctices\n",
    "---\n",
    "- [Input pipeline optimization](#Input-pipeline-optimization)\n",
    "- [Data formats](#Data-formats)\n",
    "- [Common fused Ops](#Common-fused-Ops)\n",
    "- [RNN Performance](#RNN-Performance)\n",
    "- [Building and installing from source](#Building-and-installing-from-source)\n",
    "\n",
    "### Input pipeline optimization\n",
    "---\n",
    "常见的图片读取主要有以下流程：load image > decode image into tensor > crop and pad > flip and dissort > batch\n",
    "\n",
    "1. Preprocessing on the CPU.数据预处理通常放在CPU中处理，GPU主要用于训练\n",
    "\n",
    "```python\n",
    "with tf.device('/cpu:0'):\n",
    "    distorted_inputs = load_and_distort_image()\n",
    "```\n",
    "如果使用`tf.estimator.Estimator`则input function自动在CPU中处理。\n",
    "\n",
    "2. Using the tf.data API.tf.data使用`queue_runner`来创建input pipelines.\n",
    "\n",
    "在处理large input时，不建议直接使用`feed_dict`，可以配合batch使用\n",
    "```python\n",
    "sess.run(strain_op, feed_dict={x: batch_xs, y: batch_ys})\n",
    "```\n",
    "\n",
    "3. Fused decode and crop.在处理图片数据时，建议使用 **`tf.image.decode_and_crop_jpeg`** 方法，该方法会先crop，然后在decode，可以明显提高处理效率。\n",
    "\n",
    "```python\n",
    "def _image_preprocess_fn(image_buffer):\n",
    "    # one-D\n",
    "    # extract image shape from raw jpeg image buffer\n",
    "    image_shape = tf.image.extract_jpeg_shape(image_buffer)\n",
    "    \n",
    "    # get a crop window with distorted bounding box\n",
    "    sample_distorted_bounding_box = tf.image.sample_distorted_bounding_box(image_shape, ...)\n",
    "    bbox_begin, bbox_size, distort_bbox = sample_distorted_bounding_box\n",
    "    \n",
    "    # Decode and crop image\n",
    "    offset_y, offset_x, _ = tf.unstack(bbox_begin)\n",
    "    target_height, target_width, _ = tf.unstack(bbox_size)\n",
    "    \n",
    "    crop_window = tf.stack([offset_y, offset_x, target_height, target_width])\n",
    "    cropped_image = tf.image.decode_and_crop_jpeg(image, crop_window)\n",
    "```\n",
    "4. Use large files instead of large numbers of small files.\n",
    "\n",
    "\n",
    "### Data formats\n",
    "---\n",
    "tensorflow接收两种四维的图片数据格式NCHW and NHWC.\n",
    "- NCHW or channel_first 主要用于NVIDIA GPUs using cuDNN\n",
    "- NHWC or channel_last tensorflow默认接收格式，在CPU处理中速度快\n",
    "\n",
    "### Common fused Ops\n",
    "---\n",
    "```python\n",
    "bn = tf.layer.batch_normalization(input_layers, fused=True, ..data_format='NCHW')\n",
    "```\n",
    "### RNN Performance\n",
    "---\n",
    "- `tf.nn.static_rnn`\n",
    "- `tf.nn.dynamic_rnn`适合用于长序列训练。\n",
    "\n",
    "### Building and installing from source\n",
    "---\n",
    "## Optimizing for GPU\n",
    "---\n",
    "为实现并行处理，需要对模型进行复制，称为towers，把每个tower放到每个GPU上，每个tower操作不同的一个batch数据，然后更新变量\n",
    "## Optimizing for CPU\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Building High-Performance Model\n",
    "---\n",
    "- build the model with both NHWC and NCHW\n",
    "\n",
    "NHWC在CPU上运行较快。NCHW在GPU上运行较快\n",
    "\n",
    "- Use Fused Batch-Normalization\n",
    "\n",
    "```python\n",
    "bn = tf.contrib.layers.batch_norm(input_layer, fused=True, data_format='NCHW', scope=scope)\n",
    "```\n",
    "- variable Distribution and Gradient Aggregation\n",
    "\n",
    "- Parameter Server Variables\n",
    "- Replicated Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 dataset_performance\n",
    "---\n",
    "```python\n",
    "# use num_parallel_calls cpu核数\n",
    "dataset = dataset.map(map_func, num_parallel_calls)\n",
    "\n",
    "dataset = dataset.batch(batch_size)\n",
    "# use prefetch\n",
    "dataset = dataset.prefetch(buffer_size=FLAGS.prefetch_buffer_size)\n",
    "```\n",
    "or use dataset.apply\n",
    "```python\n",
    "dataste = dataset.apply(tf.contrib.data.map_and_batch(map_func, batch_size))\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
