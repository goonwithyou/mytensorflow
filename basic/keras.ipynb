{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### a densely-connected network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# this model include a input layers and three dense layers\n",
    "# return a tensor\n",
    "inputs = Input(shape=(784,))\n",
    "\n",
    "# a layer is callable on a tensor, and return a tensor\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# start training\n",
    "model.fit(data, labels)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Multi-input and multi-output models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./image/multi-input-multi-output-graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "main_input = Input(shape=(100,), dtype='int32', name='main_input')\n",
    "\n",
    "x = Embedding(output_dim=512, input_dim=10000, input_length=100)(main_input)\n",
    "\n",
    "lstm_out = LSTM(32)(x)\n",
    "\n",
    "auxiliary_output = Dense(1, activation='sigmoid', name='aux_output')(lstm_out)\n",
    "\n",
    "auxiliary_input = Input(shape=(5,), name='aux_input')\n",
    "x = keras.layers.concatenate([lstm_out, auxiliary_input])\n",
    "\n",
    "x = Dense(64 activation='relu')(x)\n",
    "x = Dense(64 activation='relu')(x)\n",
    "x = Dense(64 activation='relu')(x)\n",
    "\n",
    "main_output = Dense(1, activation='sigmoid', name='main_output')(x)\n",
    "\n",
    "model = Model(inputs=[main_input, auxiliary_input], outputs=[main_output, auxiliary_output])\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', loss_weights=[1., 0.2])\n",
    "\n",
    "model.fit([headline_data, additional_data], [labels, labels], epochs=50, batch_size=32)\n",
    "# or\n",
    "# model.compile(optimizer='rmsprop',\n",
    "#               loss={'main_input': 'binary_crossentropy', 'aux_input': 'binary_crossentropy'},\n",
    "#               loss_weights={'main_output': 1., 'aux_output': 0.2})\n",
    "\n",
    "# model.fit({'main_input': headline_data, 'aux_input': additional_data},\n",
    "#           {'main_output': labels, 'aux_output': labels},\n",
    "#           epochs=50, batch_size=32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Shared layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import keras\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "tweet_a = Input(shape=(280, 256))\n",
    "tweet_b = Input(shape=(280, 256))\n",
    "\n",
    "shared_lstm = LSTM(64)\n",
    "\n",
    "encoded_a = shared_lstm(tweet_a)\n",
    "encoded_b = shared_lstm(tweet_b)\n",
    "\n",
    "merged_vector = keras.layers.concatenate([encoded_a, encoded_b])\n",
    "\n",
    "predictions = Dense(1, activation='sigmoid')(merged_vector)\n",
    "\n",
    "model = Model(inputs=[tweet_a, tweet_b], outputs=predictions)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit([data_a, data_b], labels, epochs=10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### The concept of layer 'node'\n",
    "\n",
    "input_shape, get_inout_shape_at(), output, get_output_at()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "a = Input(shape=(280, 256))\n",
    "\n",
    "lstm = LSTM(32)\n",
    "encoded_a = lstm(a)\n",
    "\n",
    "assert lstm.output == encoded_a\n",
    "```\n",
    "if the layer has multiple inputs:\n",
    "```python\n",
    "a = Input(shape=(280, 256))\n",
    "b = Input(shape=(280, 256))\n",
    "\n",
    "lstm = LSTM(32)\n",
    "encoded_a = lstm(a)\n",
    "encoded_b = lstm(b)\n",
    "\n",
    "assert lstm.get_output_at(0) == encoded_a\n",
    "assert lstm.get_output_at(1) == encoded_b\n",
    "```\n",
    "input_shape\n",
    "```python\n",
    "a = Input(shape=(32, 32, 3))\n",
    "b = Input(shape=(64, 64, 3))\n",
    "\n",
    "conv = Conv2D(16, (3, 3), padding='same')\n",
    "conved_a = conv(a)\n",
    "\n",
    "# Only one input so far, the following will work:\n",
    "assert conv.input_shape == (None, 32, 32, 3)\n",
    "\n",
    "conved_b = conv(b)\n",
    "# now the `.input_shape` property wouldn't work, but this does:\n",
    "assert conv.get_input_shape_at(0) == (None, 32, 32, 3)\n",
    "assert conv.get_input_shape_at(1) == (None, 64, 64, 3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Inception module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input\n",
    "\n",
    "input_img = Input(shape(256, 256, 3))\n",
    "\n",
    "tower_1 = Conv2D(64, (1, 1), padding='same', activation='relu')(input_img)\n",
    "tower_1 = Conv2D(64, (3, 3), padding='same', activation='relu')(tower_1)\n",
    "\n",
    "tower_2 = Conv2D(64, (1, 1), padding='same', activation='relu')(input_img)\n",
    "tower_2 = Conv2D(64, (5, 5), padding='same', activation='relu')(tower_2)\n",
    "\n",
    "tower_3 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(input_img)\n",
    "tower_3 = Conv2D(64, (1, 1), padding='same', activation='relu')(tower_3)\n",
    "\n",
    "output = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Residual connection on a convolution layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from keras.layers import Conv2D, Input\n",
    "\n",
    "x = Input(shape=(256, 256, 3))\n",
    "\n",
    "y = Conv2D(3, (3, 3), padding='same')(x)\n",
    "\n",
    "z = keras.layers.add([x, y])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Shared vision model\n",
    "\n",
    "可以理解为一个模型由多个模型组成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten\n",
    "from keras.models import Model\n",
    "\n",
    "digit_input = Input(shape=(27, 27, 1))\n",
    "x = Conv2D(64, (3, 3))(digit_input)\n",
    "x = Conv2D(64, (3, 3))(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "out = Flatten()(x)\n",
    "\n",
    "vision_model = Model(digit_input, out)\n",
    "\n",
    "digit_a = Input(shape=(27, 27, 1))\n",
    "digit_b = Input(shape=(27, 27, 1))\n",
    "\n",
    "out_a = vision_model(digit_a)\n",
    "out_b = vision_model(digit_b)\n",
    "\n",
    "concatenated = keras.layers.concatenate([out_a, out_b])\n",
    "out = Dense(1, activation='sigmoid')(concatenated)\n",
    "\n",
    "classification_model = Model([digit_a, digit_b], out)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Visual question answering model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "vision_model = Sequential()\n",
    "vision_model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)))\n",
    "vision_model.add(Conv2D(64, (3, 3), activation='relu'))# 222\n",
    "vision_model.add(MaxPooling2D((2, 2)))# 111\n",
    "\n",
    "vision_model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))#111\n",
    "vision_model.add(Conv2D(128, (3, 3), activation='relu'))#109\n",
    "vision_model.add(MaxPooling2D((2, 2)))#54\n",
    "\n",
    "vision_model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))#54\n",
    "vision_model.add(Conv2D(256, (3, 3), activation='relu'))#52\n",
    "vision_model.add(MaxPooling2D((2, 2)))#26\n",
    "\n",
    "vision_model.add(Flatten())\n",
    "\n",
    "image_input = Input(shape=(224, 224, 3))\n",
    "encoded_image = vision_model(image_input)\n",
    "\n",
    "question_input = Input(shape=(100,), dtype='int32')\n",
    "embedded_question = Embedding(input_dim=10000, output_dim=256, input_length=100)(question_input)\n",
    "encoded_question = LSTM(256)(embedded_question)\n",
    "\n",
    "merged = keras.layers.concatenate([encoded_question, encoded_image])\n",
    "\n",
    "output = Dense(1000, activation='softmax')(merged)\n",
    "\n",
    "vqa_model = Model(inputs=[image_input, question_input], outputs=output)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Video question answering model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "video_input = Input(shape=(100, 224, 224, 3))\n",
    "\n",
    "encoded_frame_sequence = TimeDistributed(vision_model)(video_input)\n",
    "encoded_video = LSTM(256)(encoded_frame_sequence)\n",
    "\n",
    "question_encoder = Model(inputs=question_input, outputs=encoded_question)\n",
    "\n",
    "video_question_input = Input(shape=(100,), dtype='int32')\n",
    "encoded_video_question = question_encoder(video_question_input)\n",
    "\n",
    "merged = keras.layers.concatenate([encoded_video, encoded_video_question])\n",
    "\n",
    "output = Dense(1000, activation='softmax')(merged)\n",
    "\n",
    "video_qa_model = Model(inputs=[video_input, video_question_input], outputs=output)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='border:none;border-top:3px solid red'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `model.layers`is a flattened list of the layers comprising the model.\n",
    "- `model.input`is the list of input tensors of the model\n",
    "- `model.outputs`\n",
    "- `model.summary()`prints a summary representation\n",
    "- `model.get_config()`return a dictionary containing the configuration of the model.\n",
    "    - `Model.from_config()`\n",
    "    - `Sequential.from_config()`\n",
    "- `model.get_weights()`return a list of all weight tensors in the model.\n",
    "- `model.set_weights(weights)`sets the values of the weights of the model.\n",
    "- `model.to_json()`return a representation of the model as a json string.only the architecture.\n",
    "    - `keras.models.model_from_json()`\n",
    "- `model.to_yaml()`return a representation of the model as a yaml string ,only architecture.\n",
    "    - `keras.models.model_from_yaml()`\n",
    "- `model.save_weights(filepath)`save the weights of the model as a HDF5 file.\n",
    "    - `model.load_weights(filepath, by_name=False)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='border:none;border-top:3px solid red;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "compile(self, optimizer, loss=None, metrics=None)\n",
    "\n",
    "hist = fit(self, x=None, y=None, batch_size=None, epochs=1, validation_data=None, shuffle-True)\n",
    "hist.history\n",
    "\n",
    "evaluate(self, x=None, y=None, batch_size=None, sample_weight=None, **kwargs)\n",
    "\n",
    "pred = predict(self, x, batch_size=None, verbose=0, steps=None)\n",
    "\n",
    "loss = train_on_batch(self, x, y, sample_weight=None, class_weight=None)\n",
    "\n",
    "loss = test_on_batch(self, ...)\n",
    "\n",
    "pred = predict_on_batch(self, x)\n",
    "\n",
    "hist = fit_generator(self, generator, ...)\n",
    "\n",
    "loss = evaluate_generator(self, generator, ...)\n",
    "\n",
    "pred = predict_generator(self, generator, ...)\n",
    "\n",
    "layer = get_layer(self, name=None, index=None)\n",
    "```\n",
    "\n",
    "<hr style='border:none;border-top:3px solid red;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 layers\n",
    "\n",
    "- `layer.get_weights()`\n",
    "- `layer.set_weights()`\n",
    "- `layer.get_config()`\n",
    "- `layer.input`\n",
    "- `layer.output`\n",
    "- `layer.input_shape`\n",
    "- `layer.output_shape`\n",
    "- `layer.get_input_at()`\n",
    "- `layer.get_output_at()`\n",
    "- `layer.get_input_shape_at()`\n",
    "- `layer.get_output_shape_at()`\n",
    "\n",
    "\n",
    "## 4.1 CoreLayers\n",
    "\n",
    "**Dense**\n",
    "```python\n",
    "keras.layers.Dense(units, activation)\n",
    "```\n",
    "\n",
    "**Activation**\n",
    "```python\n",
    "keras.layers.Activation(activation)\n",
    "```\n",
    "\n",
    "**Dropout**\n",
    "```python\n",
    "keras.layers.Dropout(rate, noise_shape=None, seed=None)\n",
    "```\n",
    "\n",
    "**Flatten**\n",
    "```python\n",
    "keras.layers.Flatten(data_format=None)\n",
    "```\n",
    "\n",
    "**Input**\n",
    "```python\n",
    "keras.engine.input_layer.Input()\n",
    "```\n",
    "\n",
    "**Reshape**\n",
    "```python\n",
    "# Reshape an output to a certain shape\n",
    "keras.layers.Reshape(target_shape)\n",
    "```\n",
    "\n",
    "**Permute**\n",
    "```python\n",
    "# 置换维度\n",
    "model = Sequential()\n",
    "model.add(Permute(2, 1), input_shape=(10, 64)) # output is (None, 64, 10)\n",
    "```\n",
    "\n",
    "**RepeatVector**\n",
    "```python\n",
    "keras.layers.RepeatVector(n)\n",
    "# eg:\n",
    "model.add(Dense(32, input_dim=32))\n",
    "model.add(RepeatVector(3)) # output_shape=(None, 3, 32)\n",
    "```\n",
    "\n",
    "**Lambda**\n",
    "```python\n",
    "keras.layers.Lambda(function, output_shape=None, mask=None, arguments=None)\n",
    "```\n",
    "\n",
    "**ActivityRegularization**\n",
    "```python\n",
    "keras.layers.ActivityRegularization(l1=0.0, l2=0.0)\n",
    "```\n",
    "\n",
    "**Masking**\n",
    "```python\n",
    "keras.layers.Masking(mask_value=0.0)\n",
    "```\n",
    "\n",
    "**SpatialDropout1D**\n",
    "```python\n",
    "keras.layers.SpatialDropout1D(rate)\n",
    "```\n",
    "\n",
    "**SpatialDropout2D**\n",
    "```python\n",
    "keras.layers.SpatialDropout2D(rate, data_format=None)\n",
    "```\n",
    "\n",
    "**SpatialDropout3D**\n",
    "```python\n",
    "keras.layers.SpatialDropout3D(rate)\n",
    "```\n",
    "\n",
    "## 4.2 Convolutional Layers\n",
    "\n",
    "```python\n",
    "keras.layers.Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', \n",
    "                    data_format=None, dilation_rate=(1, 1), activation=None, \n",
    "                    use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', \n",
    "                    kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, \n",
    "                    kernel_constraint=None, bias_constraint=None, **kwargs)\n",
    "```\n",
    "```python\n",
    "Conv1D\n",
    "SeparableConv1D\n",
    "SeparableConv2D\n",
    "Conv2DTranspose\n",
    "Conv3D\n",
    "Cropping1D\n",
    "Cropping2D\n",
    "Cropping3D\n",
    "UpSampling1D\n",
    "UpSampling2D\n",
    "UpSampling3D\n",
    "ZeroPadding1D\n",
    "ZeroPadding2D\n",
    "ZeroPadding3D\n",
    "```\n",
    "\n",
    "## 4.3 Pooling Layers\n",
    "\n",
    "```python\n",
    "# 如果stride=None,步长默认为pool_size\n",
    "keras.layers.MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)\n",
    "\n",
    "AveragePooling2D\n",
    "\n",
    "GlobalMaxPooling2D\n",
    "\n",
    "GlobalAveragePooling2D\n",
    "\n",
    "```\n",
    "\n",
    "## 4.4 Locally connected layers\n",
    "\n",
    "```python\n",
    "# LocallyConnected2D layer works similarly to the Conv2D layer.\n",
    "keras.layers.LocallyConnected2D(filters, kernel_size, strides=(1, 1), padding='valid', \n",
    "                                data_format=None, activation=None, use_bias=True, \n",
    "                                kernel_initializer='glorot_uniform', bias_initializer='zeros', \n",
    "                                kernel_regularizer=None, bias_regularizer=None, \n",
    "                                activity_regularizer=None, \n",
    "                                kernel_constraint=None, bias_constraint=None, **kwargs)\n",
    "```\n",
    "\n",
    "## 4.5 RNN\n",
    "\n",
    "```python\n",
    "keras.layers.RNN(cell, return_sequences=False, return_state=False, go_backwards=False, \n",
    "                 stateful=False, unroll=False, **kwargs)\n",
    "\n",
    "# fully connected RNN where the output is to be fed back to input.\n",
    "SimpleRNN\n",
    "\n",
    "# gated recurrent unit\n",
    "GRU\n",
    "\n",
    "# long short term memory layer\n",
    "LSTM\n",
    "\n",
    "# convolutional LSTM\n",
    "ConvLSTM2D\n",
    "\n",
    "# cell class for simpleRNN\n",
    "SimpleRNNCell\n",
    "\n",
    "GRUCell\n",
    "LSTMCell\n",
    "\n",
    "CuDNNGRU\n",
    "CuDNNLSTM\n",
    "```\n",
    "\n",
    "## 4.6 Embedding\n",
    "\n",
    "```python\n",
    "keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform', embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None, **kwargs)\n",
    "```\n",
    "## 4.7 Merge Layers\n",
    "\n",
    "```python\n",
    "Add\n",
    "\n",
    "Substract\n",
    "\n",
    "Multiply\n",
    "\n",
    "Average\n",
    "\n",
    "Maximum\n",
    "\n",
    "Concatenate\n",
    "\n",
    "Dot\n",
    "```\n",
    "## 4.8 Activation layers\n",
    "\n",
    "```python\n",
    "LeakyReLU\n",
    "PReLU\n",
    "ELU\n",
    "ThresholderReLU\n",
    "softmax\n",
    "ReLU\n",
    "\n",
    "```\n",
    "## 4.9 Normalization layers\n",
    "\n",
    "```python\n",
    "BatchNormalization\n",
    "\n",
    "```\n",
    "\n",
    "## 4.10 GaussianNoise\n",
    "\n",
    "```python\n",
    "GaussianNoise\n",
    "GaussianDropout\n",
    "AlphaDropout\n",
    "\n",
    "```\n",
    "\n",
    "## 4.11 Layer wrappers\n",
    "```python\n",
    "TimeDistributed\n",
    "\n",
    "Bidirectional\n",
    "\n",
    "\n",
    "```\n",
    "<hr style='border:none;border-top:3px solid red;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Preprocessing\n",
    "\n",
    "## 5.1 Sequence Preprocessing\n",
    "```python\n",
    "TimeseriesGenerator\n",
    "\n",
    "pad_sequences\n",
    "\n",
    "skipgrams\n",
    "\n",
    "make_sampling_table\n",
    "\n",
    "```\n",
    "## 5.2 Text Preprocessing\n",
    "\n",
    "```python\n",
    "Tokenizer\n",
    "\n",
    "hashing_trick\n",
    "\n",
    "one_hot\n",
    "\n",
    "text_to_word_sequence\n",
    "```\n",
    "\n",
    "## 5.3 Image Preprocessing\n",
    "\n",
    "```python\n",
    "ImageDataGenerator\n",
    "\n",
    "apply_transform\n",
    "\n",
    "fit\n",
    "\n",
    "flow\n",
    "\n",
    "flow_from_directory\n",
    "\n",
    "get_random_transform\n",
    "\n",
    "random_transform\n",
    "\n",
    "standardize\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Losses\n",
    "\n",
    "\n",
    "- mean_squared_error\n",
    "- mean_absolute_error\n",
    "- mean_absolute_percentage_error\n",
    "- mean_squared_logarithmic_error\n",
    "- squared_hinge\n",
    "- hinge\n",
    "- categorical_hinge\n",
    "- logcosh\n",
    "- categorical_crossentropy\n",
    "- sparse_categorical_crossentropy\n",
    "- binary_crossentropy\n",
    "- kullback_leibler_divergence\n",
    "- poisson\n",
    "- cosine_proximity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Metrics\n",
    "\n",
    "- binary_accuracy\n",
    "- categorical_accuracy\n",
    "- sparse_categorical_accuracy\n",
    "- top_k_categorical_accuracy\n",
    "- sparse_top_k_categorical_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Optimizers\n",
    "\n",
    "- SGD\n",
    "- RMSprop\n",
    "- Adagrad\n",
    "- Adadelta\n",
    "- Adam\n",
    "- Adamax\n",
    "- Nadam\n",
    "- TFOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 Activations\n",
    "\n",
    "- softmax\n",
    "- elu\n",
    "- selu\n",
    "- softplus\n",
    "- softsign\n",
    "- relu\n",
    "- tanh\n",
    "- sigmoid\n",
    "- hard_sigmoid\n",
    "- linear\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 Callbacks\n",
    "\n",
    "- Callback\n",
    "- BaseLogger\n",
    "- ProgbarLogger\n",
    "- History\n",
    "- ModelCheckPoint\n",
    "- EarlyStopping\n",
    "- RemoteMonitor\n",
    "- LearningRateScheduler\n",
    "- TensorBoard\n",
    "- ReduceLROnPlateau\n",
    "- CSVLogger\n",
    "- LambdaCallback\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11 Datasets\n",
    "\n",
    "- cifar\n",
    "- imdb\n",
    "- reuters\n",
    "- mnist\n",
    "- fashion-mnist\n",
    "- boston_housing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 Application\n",
    "\n",
    "- Xception\n",
    "- VGG16\n",
    "- VGG19\n",
    "- ResNet50\n",
    "- InceptionV3\n",
    "- InceptionResNetV2\n",
    "- MobileNet\n",
    "- DenseNet\n",
    "- NASNet\n",
    "- MobileNetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13 Backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14 Initializers\n",
    "\n",
    "- Zeros\n",
    "- Ones\n",
    "- Constant\n",
    "- RandomNormal\n",
    "- RandomUniform\n",
    "- TruncatedNormal\n",
    "- VarianceScaling\n",
    "- Orthogonal\n",
    "- Identity\n",
    "- lecun_uniform\n",
    "- glorot_normal\n",
    "- glorot_uniform\n",
    "- he_normal\n",
    "- lecun_normal\n",
    "- he_uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15 Regularizers\n",
    "\n",
    "- regularizers.l1\n",
    "- regularizers.l2\n",
    "- regularizers.l1_l2\n",
    "\n",
    "# 16 Constraints\n",
    "\n",
    "- max_norm\n",
    "- non_neg\n",
    "- unit_norm\n",
    "- min_max_norm\n",
    "\n",
    "# 17 Visualization\n",
    "\n",
    "- `keras.utils.vis_utils.plot_model`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
