{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### a densely-connected network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# this model include a input layers and three dense layers\n",
    "# return a tensor\n",
    "inputs = Input(shape=(784,))\n",
    "\n",
    "# a layer is callable on a tensor, and return a tensor\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# start training\n",
    "model.fit(data, labels)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Multi-input and multi-output models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./image/multi-input-multi-output-graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "main_input = Input(shape=(100,), dtype='int32', name='main_input')\n",
    "\n",
    "x = Embedding(output_dim=512, input_dim=10000, input_length=100)(main_input)\n",
    "\n",
    "lstm_out = LSTM(32)(x)\n",
    "\n",
    "auxiliary_output = Dense(1, activation='sigmoid', name='aux_output')(lstm_out)\n",
    "\n",
    "auxiliary_input = Input(shape=(5,), name='aux_input')\n",
    "x = keras.layers.concatenate([lstm_out, auxiliary_input])\n",
    "\n",
    "x = Dense(64 activation='relu')(x)\n",
    "x = Dense(64 activation='relu')(x)\n",
    "x = Dense(64 activation='relu')(x)\n",
    "\n",
    "main_output = Dense(1, activation='sigmoid', name='main_output')(x)\n",
    "\n",
    "model = Model(inputs=[main_input, auxiliary_input], outputs=[main_output, auxiliary_output])\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', loss_weights=[1., 0.2])\n",
    "\n",
    "model.fit([headline_data, additional_data], [labels, labels], epochs=50, batch_size=32)\n",
    "# or\n",
    "# model.compile(optimizer='rmsprop',\n",
    "#               loss={'main_input': 'binary_crossentropy', 'aux_input': 'binary_crossentropy'},\n",
    "#               loss_weights={'main_output': 1., 'aux_output': 0.2})\n",
    "\n",
    "# model.fit({'main_input': headline_data, 'aux_input': additional_data},\n",
    "#           {'main_output': labels, 'aux_output': labels},\n",
    "#           epochs=50, batch_size=32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Shared layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import keras\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "tweet_a = Input(shape=(280, 256))\n",
    "tweet_b = Input(shape=(280, 256))\n",
    "\n",
    "shared_lstm = LSTM(64)\n",
    "\n",
    "encoded_a = shared_lstm(tweet_a)\n",
    "encoded_b = shared_lstm(tweet_b)\n",
    "\n",
    "merged_vector = keras.layers.concatenate([encoded_a, encoded_b])\n",
    "\n",
    "predictions = Dense(1, activation='sigmoid')(merged_vector)\n",
    "\n",
    "model = Model(inputs=[tweet_a, tweet_b], outputs=predictions)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit([data_a, data_b], labels, epochs=10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### The concept of layer 'node'\n",
    "\n",
    "input_shape, get_inout_shape_at(), output, get_output_at()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "a = Input(shape=(280, 256))\n",
    "\n",
    "lstm = LSTM(32)\n",
    "encoded_a = lstm(a)\n",
    "\n",
    "assert lstm.output == encoded_a\n",
    "```\n",
    "if the layer has multiple inputs:\n",
    "```python\n",
    "a = Input(shape=(280, 256))\n",
    "b = Input(shape=(280, 256))\n",
    "\n",
    "lstm = LSTM(32)\n",
    "encoded_a = lstm(a)\n",
    "encoded_b = lstm(b)\n",
    "\n",
    "assert lstm.get_output_at(0) == encoded_a\n",
    "assert lstm.get_output_at(1) == encoded_b\n",
    "```\n",
    "input_shape\n",
    "```python\n",
    "a = Input(shape=(32, 32, 3))\n",
    "b = Input(shape=(64, 64, 3))\n",
    "\n",
    "conv = Conv2D(16, (3, 3), padding='same')\n",
    "conved_a = conv(a)\n",
    "\n",
    "# Only one input so far, the following will work:\n",
    "assert conv.input_shape == (None, 32, 32, 3)\n",
    "\n",
    "conved_b = conv(b)\n",
    "# now the `.input_shape` property wouldn't work, but this does:\n",
    "assert conv.get_input_shape_at(0) == (None, 32, 32, 3)\n",
    "assert conv.get_input_shape_at(1) == (None, 64, 64, 3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Inception module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input\n",
    "\n",
    "input_img = Input(shape(256, 256, 3))\n",
    "\n",
    "tower_1 = Conv2D(64, (1, 1), padding='same', activation='relu')(input_img)\n",
    "tower_1 = Conv2D(64, (3, 3), padding='same', activation='relu')(tower_1)\n",
    "\n",
    "tower_2 = Conv2D(64, (1, 1), padding='same', activation='relu')(input_img)\n",
    "tower_2 = Conv2D(64, (5, 5), padding='same', activation='relu')(tower_2)\n",
    "\n",
    "tower_3 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(input_img)\n",
    "tower_3 = Conv2D(64, (1, 1), padding='same', activation='relu')(tower_3)\n",
    "\n",
    "output = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Residual connection on a convolution layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from keras.layers import Conv2D, Input\n",
    "\n",
    "x = Input(shape=(256, 256, 3))\n",
    "\n",
    "y = Conv2D(3, (3, 3), padding='same')(x)\n",
    "\n",
    "z = keras.layers.add([x, y])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Shared vision model\n",
    "\n",
    "可以理解为一个模型由多个模型组成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten\n",
    "from keras.models import Model\n",
    "\n",
    "digit_input = Input(shape=(27, 27, 1))\n",
    "x = Conv2D(64, (3, 3))(digit_input)\n",
    "x = Conv2D(64, (3, 3))(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "out = Flatten()(x)\n",
    "\n",
    "vision_model = Model(digit_input, out)\n",
    "\n",
    "digit_a = Input(shape=(27, 27, 1))\n",
    "digit_b = Input(shape=(27, 27, 1))\n",
    "\n",
    "out_a = vision_model(digit_a)\n",
    "out_b = vision_model(digit_b)\n",
    "\n",
    "concatenated = keras.layers.concatenate([out_a, out_b])\n",
    "out = Dense(1, activation='sigmoid')(concatenated)\n",
    "\n",
    "classification_model = Model([digit_a, digit_b], out)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Visual question answering model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "vision_model = Sequential()\n",
    "vision_model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)))\n",
    "vision_model.add(Conv2D(64, (3, 3), activation='relu'))# 222\n",
    "vision_model.add(MaxPooling2D((2, 2)))# 111\n",
    "\n",
    "vision_model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))#111\n",
    "vision_model.add(Conv2D(128, (3, 3), activation='relu'))#109\n",
    "vision_model.add(MaxPooling2D((2, 2)))#54\n",
    "\n",
    "vision_model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))#54\n",
    "vision_model.add(Conv2D(256, (3, 3), activation='relu'))#52\n",
    "vision_model.add(MaxPooling2D((2, 2)))#26\n",
    "\n",
    "vision_model.add(Flatten())\n",
    "\n",
    "image_input = Input(shape=(224, 224, 3))\n",
    "encoded_image = vision_model(image_input)\n",
    "\n",
    "question_input = Input(shape=(100,), dtype='int32')\n",
    "embedded_question = Embedding(input_dim=10000, output_dim=256, input_length=100)(question_input)\n",
    "encoded_question = LSTM(256)(embedded_question)\n",
    "\n",
    "merged = keras.layers.concatenate([encoded_question, encoded_image])\n",
    "\n",
    "output = Dense(1000, activation='softmax')(merged)\n",
    "\n",
    "vqa_model = Model(inputs=[image_input, question_input], outputs=output)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Video question answering model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "video_input = Input(shape=(100, 224, 224, 3))\n",
    "\n",
    "encoded_frame_sequence = TimeDistributed(vision_model)(video_input)\n",
    "encoded_video = LSTM(256)(encoded_frame_sequence)\n",
    "\n",
    "question_encoder = Model(inputs=question_input, outputs=encoded_question)\n",
    "\n",
    "video_question_input = Input(shape=(100,), dtype='int32')\n",
    "encoded_video_question = question_encoder(video_question_input)\n",
    "\n",
    "merged = keras.layers.concatenate([encoded_video, encoded_video_question])\n",
    "\n",
    "output = Dense(1000, activation='softmax')(merged)\n",
    "\n",
    "video_qa_model = Model(inputs=[video_input, video_question_input], outputs=output)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='border:none;border-top:3px solid red'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `model.layers`is a flattened list of the layers comprising the model.\n",
    "- `model.input`is the list of input tensors of the model\n",
    "- `model.outputs`\n",
    "- `model.summary()`prints a summary representation\n",
    "- `model.get_config()`return a dictionary containing the configuration of the model.\n",
    "    - `Model.from_config()`\n",
    "    - `Sequential.from_config()`\n",
    "- `model.get_weights()`return a list of all weight tensors in the model.\n",
    "- `model.set_weights(weights)`sets the values of the weights of the model.\n",
    "- `model.to_json()`return a representation of the model as a json string.only the architecture.\n",
    "    - `keras.models.model_from_json()`\n",
    "- `model.to_yaml()`return a representation of the model as a yaml string ,only architecture.\n",
    "    - `keras.models.model_from_yaml()`\n",
    "- `model.save_weights(filepath)`save the weights of the model as a HDF5 file.\n",
    "    - `model.load_weights(filepath, by_name=False)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='border:none;border-top:3px solid red;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "compile(self, optimizer, loss=None, metrics=None)\n",
    "\n",
    "hist = fit(self, x=None, y=None, batch_size=None, epochs=1, validation_data=None, shuffle-True)\n",
    "hist.history\n",
    "\n",
    "evaluate(self, x=None, y=None, batch_size=None, sample_weight=None, **kwargs)\n",
    "\n",
    "pred = predict(self, x, batch_size=None, verbose=0, steps=None)\n",
    "\n",
    "loss = train_on_batch(self, x, y, sample_weight=None, class_weight=None)\n",
    "\n",
    "loss = test_on_batch(self, ...)\n",
    "\n",
    "pred = predict_on_batch(self, x)\n",
    "\n",
    "hist = fit_generator(self, generator, ...)\n",
    "\n",
    "loss = evaluate_generator(self, generator, ...)\n",
    "\n",
    "pred = predict_generator(self, generator, ...)\n",
    "\n",
    "layer = get_layer(self, name=None, index=None)\n",
    "```\n",
    "\n",
    "<hr style='border:none;border-top:3px solid red;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 layers\n",
    "\n",
    "- `layer.get_weights()`\n",
    "- `layer.set_weights()`\n",
    "- `layer.get_config()`\n",
    "- `layer.input`\n",
    "- `layer.output`\n",
    "- `layer.input_shape`\n",
    "- `layer.output_shape`\n",
    "- `layer.get_input_at()`\n",
    "- `layer.get_output_at()`\n",
    "- `layer.get_input_shape_at()`\n",
    "- `layer.get_output_shape_at()`\n",
    "\n",
    "<hr style='border:none;border-top:3px solid red;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 CoreLayers\n",
    "\n",
    "**Dense**\n",
    "```python\n",
    "keras.layers.Dense(units, activation)\n",
    "```\n",
    "\n",
    "**Activation**\n",
    "```python\n",
    "keras.layers.Activation(activation)\n",
    "```\n",
    "\n",
    "**Dropout**\n",
    "```python\n",
    "keras.layers.Dropout(rate, noise_shape=None, seed=None)\n",
    "```\n",
    "\n",
    "**Flatten**\n",
    "```python\n",
    "keras.layers.Flatten(data_format=None)\n",
    "```\n",
    "\n",
    "**Input**\n",
    "```python\n",
    "keras.engine.input_layer.Input()\n",
    "```\n",
    "\n",
    "**Reshape**\n",
    "```python\n",
    "# Reshape an output to a certain shape\n",
    "keras.layers.Reshape(target_shape)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.engine.input_layer.Input?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.layers.Input?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
